ğŸ  California Housing Price Prediction
ğŸ“Œ Project Overview

This project focuses on predicting median house values in California districts using regression-based machine learning models.
The objective is to build a robust, interpretable model while carefully handling data skewness, multicollinearity, and target censoring.

ğŸ“‚ Dataset Description

Source: California Housing Dataset

Rows: ~20,640 (before preprocessing)

Features: 8 numerical predictors

Target: median_house_value

Key Features

median_income

housing_median_age

total_rooms

total_bedrooms

population

households

latitude

longitude

ğŸ” Exploratory Data Analysis (EDA)
Key Findings

No missing values in most features

total_bedrooms contained missing values â†’ mean imputation applied

Target variable is right-skewed

Strong price cap at $500,000, causing artificial clustering

median_income shows the strongest correlation with house price (~0.67)

Several features are highly correlated, indicating multicollinearity

Visual Insights

Histogram revealed skewed distribution and capped values

Scatter plots confirmed strong linear relationship between income and price

Geographic clustering observed around major urban areas

âš™ï¸ Data Preprocessing
1ï¸âƒ£ Target Censoring

Rows with median_house_value == 500000 were removed

Reason: These values represent a capped ceiling, not true prices

2ï¸âƒ£ Target Transformation

Log transformation applied:

log(median_house_value)


Reduced skewness

Improved stability for linear models

3ï¸âƒ£ Missing Value Handling

total_bedrooms filled using mean imputation

4ï¸âƒ£ Feature Scaling

StandardScaler applied

Required for linear and regularized models

ğŸ¤– Models Implemented
ğŸ”¹ Linear Regression

Used as a baseline

Performance limited by multicollinearity

ğŸ”¹ Ridge Regression âœ… (Final Model)

Addresses multicollinearity

Provides stable coefficients

Best generalization performance

Configuration:

Alpha: 0.01

Target: log-transformed

Scaled features

Performance:

RÂ² â‰ˆ 0.62

RMSE (log scale) â‰ˆ 0.33

ğŸ”¹ Random Forest Regression âŒ

Tested to capture non-linear relationships

Underperformed due to:

Small dataset size

Predominantly linear relationships

Weak interaction effects

ğŸ“Š Model Comparison
Model	Target	RÂ²
Linear Regression	log	~0.60
Ridge Regression	log	~0.62
Random Forest	raw	~0.61
ğŸ§  Key Learnings

Model complexity does not guarantee better performance

Regularization is critical when features are correlated

Log transformation improves stability for skewed targets

Tree-based models are not always optimal for small, linear datasets

Proper EDA directly informs model choice

âœ… Final Conclusion

Ridge Regression with a log-transformed target provided the most stable and interpretable results for California housing price prediction, outperforming both basic linear regression and tree-based models.

ğŸ›  Tech Stack

Python

Pandas, NumPy

Seaborn, Matplotlib

Scikit-learn

ğŸš€ Future Improvements

RidgeCV for optimal alpha selection

Polynomial and interaction features

Residual diagnostics and assumption checks

Gradient Boosting on engineered features

ğŸ‘ Closing Note

This project demonstrates an end-to-end machine learning workflow:
EDA â†’ Feature Engineering â†’ Model Selection â†’ Evaluation â†’ Documentation